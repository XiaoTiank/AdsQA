<p align="center">
    <img src="./assets/project-name.png" alt="Project cover image"/> <br />
</p>


<div align="center">
<!-- ğŸ” <b>Paper</b>: <i><a href="#">Coming Soon</a></i> | 
  ğŸ“Š <b>Benchmark</b>: <i>Coming Soon</i> |
  ğŸ¤– <b>Model</b>: <i>Coming Soon</i> 
-->   
    <p align="center">
        <i>Keywords: Advertisement Videos, VideoQA, Multimodal Reasoning, GRPO</i>
    </p>
</div>

----
<img align="center" src="./assets/video.png" >

<img align="center" src="./assets/Figure 1.png" >

AdsQA is the **first large-scale benchmark** targeting advertisement video understanding through **LLMs**. Ad videos are rich, symbolic, emotionally charged, and ideal for evaluating cognitive-level reasoning beyond physical perception. 

- **ğŸŒŸ Why ads?** Unlike typical visual data, ads are professionally crafted to convey themes, metaphors, and targeted emotions.
- **ğŸ“¦ Whatâ€™s AdsQA?** A benchmark built on 1,544 ad videos and 10,962 clips totaling 21.1 hours, annotated via a novel multi-agent pipeline.
- **ğŸš€ Our Model: ReAd-R** is a Reinforced Ad Reasoner trained using reward-based optimization, outperforming chain-of-thought and agent-based methods.
- **ğŸ¯ 5 Tasks**: Visual Concepts, Emotion, Themes, Persuasion, and Audience.



## ğŸ“ Tasks Overview
1. **Visual Concept Understanding (VU)** â€“ Identify scenes, characters, symbols.
2. **Emotion Recognition (ER)** â€“ Infer emotional undertones and user impact.
3. **Theme Extraction (TE)** â€“ Distill core message and implied storytelling.
4. **Persuasion Strategy (PS)** â€“ Decode rhetorical and marketing tactics.
5. **Audience Modeling (AM)** â€“ Predict target demographics and profiles.

## ğŸ“Š Dataset Details

<p align="center">
    <img src="./assets/Figure 2.png" width="800px"/> <br />
    <em>Figure: Statistics of AdsQA benchmark (duration, domain, regions, etc).</em>
</p>

- 1,544 ad videos from 9 domains and 6 continents.
- 7,838 open-ended QA pairs across 5 categories.
- Clips sampled and described using multi-modal pipeline (frames, ASR, descriptions).


## ğŸ§  ReAd-R: Reinforced Ad Reasoner

<p align="center">
    <img src="./assets/Figure 3.png" width="520px"/> <br />
    <em>Figure: Architecture of ReAd-R.</em>
</p>

ReAd-R simulates **human-like heuristic reasoning** via reinforcement learning (RL):

- Reward-driven answer generation with no chain-of-thought templates.
- Optimized with GRPO using self-generated reward signals.
- Supports open-ended VideoQA and is base-model agnostic.

## ğŸ§ª Experiments

<p align="center">
    <img src="./assets/table 1.png" width="800px"/> <br />
    <!-- <em>Figure: Sample predictions vs ground-truth across models.</em> -->
</p>

### Key Findings:
- AdsQA is substantially harder than typical video QA benchmarks.
- ReAd-R excels at **implicit logic** and **persuasive reasoning**.
- Chain-of-thought and multi-agent search show limited generalization.

## ğŸ§ª Case Studies

<p align="center">
    <img src="./assets/Figure 4.png" width="520px"/> <br />
    <!-- <em>Figure: Sample predictions vs ground-truth across models.</em> -->
</p>




## ğŸ› ï¸ Get Started (Coming Soon)

We will release:
- ğŸ§¾ Codebase for AdsQA annotation and evaluation.
- ğŸ¤– Checkpoints of ReAd-R and evaluation scripts.
- ğŸ§ª Toolkit for benchmarking your own models on AdsQA.
